{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('default')\n",
    "import xarray as xr\n",
    "import scipy.interpolate as interp\n",
    "\n",
    "import scipy.io as sio\n",
    "import numpy.matlib\n",
    "import cmath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose iceberg year (2002 - 2015 available)\n",
    "# Note: Iceberg Season starts in November so many datasets include dates from year-1\n",
    "season_year = 2015\n",
    "iip_url_base = 'ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G00807/' \n",
    "iip_filename = f'IIP_{season_year}IcebergSeason.csv'\n",
    "iip_url = iip_url_base + iip_filename\n",
    "r = urllib.request.urlretrieve(iip_url)\n",
    "df = pd.read_csv(r[0], converters={'TIME':str})\n",
    "df['DATETIME'] = pd.to_datetime(df['DATE'] + 'T' + df['TIME'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the min number of observations for an eligible iceberg\n",
    "min_num_obs = 10\n",
    "eligible_bergs = np.asarray(\n",
    "    df['BERG_NUMBER'].value_counts()\\\n",
    "    .loc[df['BERG_NUMBER'].value_counts() > min_num_obs].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_inds_arr = []\n",
    "\n",
    "for i in range(eligible_bergs.size):\n",
    "\n",
    "    berg_id = eligible_bergs[i]\n",
    "    berg_df = df.loc[df['BERG_NUMBER'] == berg_id]\n",
    "    \n",
    "    ind0 = berg_df.index.tolist()[0]\n",
    "    indf = berg_df.index.tolist()[-1]\n",
    "    \n",
    "    max_time_dif = np.timedelta64(24*60*3, 'm')\n",
    "    \n",
    "    chosen_inds = []\n",
    "\n",
    "    for j in range(len(berg_df)-1):\n",
    "\n",
    "        time_dif = (berg_df.DATETIME.values[j+1] - \\\n",
    "                    berg_df.DATETIME.values[j]).astype('timedelta64[m]')\n",
    "        \n",
    "        if time_dif < max_time_dif:\n",
    "            chosen_inds.append(j+ind0)\n",
    "\n",
    "        elif len(chosen_inds) > 5:\n",
    "            chosen_inds_arr.append(chosen_inds)\n",
    "            chosen_inds = []\n",
    "        else:\n",
    "            chosen_inds = []\n",
    "\n",
    "    if len(chosen_inds) > 5:\n",
    "        chosen_inds_arr.append(chosen_inds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose which iceberg track to look at (index)\n",
    "chosen_track_ind = 2\n",
    "\n",
    "berg_df = df.loc[chosen_inds_arr[chosen_track_ind]].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Iceberg:\n",
    "    \n",
    "    def __init__(self, id_num, times, lats, lons, size):\n",
    "        self.id_num = id_num\n",
    "        self.times = times\n",
    "        self.lats = lats\n",
    "        self.lons = lons\n",
    "        if type(size) == str:\n",
    "            self.length, self.width, self.height = self.get_berg_dims(size)\n",
    "        elif type(size) == list and len(size) == 3:\n",
    "            self.length, self.width, self.height = size[0], size[1], size[2]\n",
    "        else:\n",
    "            print('Invalid size argument')\n",
    "            \n",
    "    def get_berg_dims(self, size):\n",
    "        # Size must be GR, BB, SM, MED, LG, VLG\n",
    "        # See https://nsidc.org/data/g00807 for more info\n",
    "        if size == 'GR':\n",
    "            l = (0+5)/2; w = (0+5)/2; h = (0+1)/2*10\n",
    "        elif size == 'BB':\n",
    "            l = (5+15)/2; w = (5+15)/2; h = (1+5)/2*10        \n",
    "        elif size == 'SM':\n",
    "            l = (15+60)/2; w = (15+60)/2; h = (5+15)/2*10        \n",
    "        elif size == 'MED':\n",
    "            l = (60+120)/2; w = (60+120)/2; h = (15+45)/2*10               \n",
    "        elif size == 'LG':\n",
    "            l = (120)/2; w = (120)/2; h = (45+75)/2*10                \n",
    "        elif size == 'VLG':\n",
    "            # Sizes have no listed upper bound\n",
    "            l = (200+200/2)/2; w = (200+200/2)/2; h = (75+75/2)/2*10     \n",
    "        # This info for GEN is wrong!\n",
    "        elif size == 'GEN':\n",
    "            l = (120)/2; w = (120)/2; h = (45+75)/2*10            \n",
    "        else:\n",
    "            print('unknown size class')\n",
    "            l = None; w = None; h = None\n",
    "        return l, w, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "iip_berg = Iceberg(berg_df['BERG_NUMBER'].loc[0],\n",
    "                   berg_df['DATETIME'].loc[0:1].tolist(),\n",
    "                   berg_df['LATITUDE'].loc[0:1].tolist(),\n",
    "                   berg_df['LONGITUDE'].loc[0:1].tolist(),\n",
    "                   berg_df['SIZE'].loc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GLB:\n",
    "    \n",
    "    glb_url = 'http://tds.hycom.org/thredds/dodsC/GLBv0.08/expt_56.3'\n",
    "    \n",
    "    def __init__(self, berg):\n",
    "        self.ds = xr.open_dataset(self.glb_url, \n",
    "                                  decode_times=False).sel(\n",
    "                                  depth=0.0, \n",
    "                                  lat = slice(min(berg.lats)-1, max(berg.lats)+1), \n",
    "                                  lon = slice(min(berg.lons)-1, max(berg.lons)+1), \n",
    "                                  time=slice(self.convert_time(berg.times[0]), \n",
    "                                             self.convert_time(berg.times[-1])))\n",
    "        self.times = np.asarray(self.ds.time)\n",
    "        self.lats = np.asarray(self.ds.lat)\n",
    "        self.lons = np.asarray(self.ds.lon)\n",
    "        #self.water_u = self.ds.water_u\n",
    "        #self.water_u = np.asarray(self.ds.water_u)\n",
    "        self.water_u = np.asarray(self.ds.water_u)\n",
    "        self.water_v = np.asarray(self.ds.water_v)\n",
    "        self.water_temp = np.asarray(self.ds.water_temp)\n",
    "        \n",
    "    def convert_time(self, berg_time):\n",
    "        date2000 = np.datetime64('2000-01-01')\n",
    "        diff = berg_time - date2000\n",
    "        days = diff.days\n",
    "        seconds = diff.seconds\n",
    "        hours = days*24 + seconds/3600\n",
    "        return hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "glb = GLB(iip_berg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Navgem:\n",
    "    navgem_url = 'http://coastwatch.pfeg.noaa.gov/erddap/griddap/erdNavgem05D10mWind_LonPM180'\n",
    "\n",
    "    def __init__(self, berg):\n",
    "        self.ds = xr.open_dataset(self.navgem_url).sel(\n",
    "                         time=slice(self.convert_time(berg.times[0]), \n",
    "                                    self.convert_time(berg.times[-1], add_day=True)), \n",
    "                         latitude=slice(min(berg.lats)-1, max(berg.lats)+1), \n",
    "                         longitude=slice(min(berg.lons)-1, max(berg.lons)+1))\n",
    "        self.times = np.asarray(self.ds.time)\n",
    "        self.lats = np.asarray(self.ds.latitude)\n",
    "        self.lons = np.asarray(self.ds.longitude)\n",
    "        #self.wind_u = np.asarray(self.ds.wnd_ucmp_height_above_ground)\n",
    "        #self.wind_v = np.asarray(self.ds.wnd_vcmp_height_above_ground)\n",
    "                                    \n",
    "    def convert_time(self, berg_time, add_day=False):\n",
    "        if add_day:\n",
    "            one_day = pd.Timedelta('1 days')\n",
    "            date = '{}-{}-{}' .format((berg_time + one_day).year,\n",
    "                                      (berg_time + one_day).month,\n",
    "                                      (berg_time + one_day).day)\n",
    "        else:\n",
    "            date = '{}-{}-{}' .format(berg_time.year,\n",
    "                                      berg_time.month,\n",
    "                                      berg_time.day)\n",
    "        return date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno -90] NetCDF: file not found: b'http://coastwatch.pfeg.noaa.gov/erddap/griddap/erdNavgem05D10mWind_LonPM180'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-143-0ace0d69dcfe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnavgem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNavgem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miip_berg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-142-e3dd5d8ade62>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, berg)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mberg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         self.ds = xr.open_dataset(self.navgem_url).sel(\n\u001b[0m\u001b[1;32m      6\u001b[0m                          time=slice(self.convert_time(berg.times[0]), \n\u001b[1;32m      7\u001b[0m                                     self.convert_time(berg.times[-1], add_day=True)), \n",
      "\u001b[0;32m~/.conda/envs/my_root/lib/python3.6/site-packages/xarray/backends/api.py\u001b[0m in \u001b[0;36mopen_dataset\u001b[0;34m(filename_or_obj, group, decode_cf, mask_and_scale, decode_times, autoclose, concat_characters, decode_coords, engine, chunks, lock, cache, drop_variables)\u001b[0m\n\u001b[1;32m    284\u001b[0m             store = backends.NetCDF4DataStore.open(filename_or_obj,\n\u001b[1;32m    285\u001b[0m                                                    \u001b[0mgroup\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m                                                    autoclose=autoclose)\n\u001b[0m\u001b[1;32m    287\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'scipy'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m             store = backends.ScipyDataStore(filename_or_obj,\n",
      "\u001b[0;32m~/.conda/envs/my_root/lib/python3.6/site-packages/xarray/backends/netCDF4_.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(cls, filename, mode, format, group, writer, clobber, diskless, persist, autoclose)\u001b[0m\n\u001b[1;32m    250\u001b[0m                                    \u001b[0mdiskless\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdiskless\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpersist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpersist\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m                                    format=format)\n\u001b[0;32m--> 252\u001b[0;31m         \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m         return cls(ds, mode=mode, writer=writer, opener=opener,\n\u001b[1;32m    254\u001b[0m                    autoclose=autoclose)\n",
      "\u001b[0;32m~/.conda/envs/my_root/lib/python3.6/site-packages/xarray/backends/netCDF4_.py\u001b[0m in \u001b[0;36m_open_netcdf4_group\u001b[0;34m(filename, mode, group, **kwargs)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mnetCDF4\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnc4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m     \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnc4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mclose_on_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mnetCDF4/_netCDF4.pyx\u001b[0m in \u001b[0;36mnetCDF4._netCDF4.Dataset.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mnetCDF4/_netCDF4.pyx\u001b[0m in \u001b[0;36mnetCDF4._netCDF4._ensure_nc_success\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno -90] NetCDF: file not found: b'http://coastwatch.pfeg.noaa.gov/erddap/griddap/erdNavgem05D10mWind_LonPM180'"
     ]
    }
   ],
   "source": [
    "navgem = Navgem(iip_berg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
